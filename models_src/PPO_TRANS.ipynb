{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "import torch.nn as nn\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n",
    "torch.cuda.set_per_process_memory_fraction(0.75, device = 0)\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.manual_seed(52)\n",
    "np.random.seed(52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 100\n",
    "SEQUENCE_LENGTH = 100\n",
    "N_EPISODES = 500\n",
    "LEARNING_RATE = 3e-4\n",
    "TRAIN_DIR = \"../src/train_denoised/\"\n",
    "TEST_DIR = \"../src/test_denoised/\"\n",
    "\n",
    "MODEL_SAVE_PATH = \"../models/ppo_transformer_model.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerFeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(TransformerFeatureExtractor, self).__init__()\n",
    "        self.transformer = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.fc = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transformer(x).last_hidden_state\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return x\n",
    "\n",
    "class CustomTransformerPolicy(ActorCriticPolicy):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(CustomTransformerPolicy, self).__init__(*args, **kwargs)\n",
    "        self.features_dim = kwargs[\"features_extractor_kwargs\"][\"features_dim\"]\n",
    "        self.feature_extractor = TransformerFeatureExtractor(self.features_dim, 128)\n",
    "        self.fc = nn.Linear(128, self.features_dim)\n",
    "\n",
    "    def forward(self, features):\n",
    "        transformer_out = self.feature_extractor(features)\n",
    "        return self.fc(transformer_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesEnv(gym.Env):\n",
    "    def __init__(self, data, labels):\n",
    "        super(TimeSeriesEnv, self).__init__()\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.current_step = 0\n",
    "        self.observation_space = spaces.Box(low=0.0, high=1.0, shape=(SEQUENCE_LENGTH, 1), dtype=np.float32)\n",
    "        self.action_space = spaces.MultiDiscrete([3] * SEQUENCE_LENGTH) \n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        return np.array(self.data[self.current_step], dtype=np.float32)\n",
    "\n",
    "    def step(self, actions):\n",
    "        true_labels = self.labels[self.current_step]\n",
    "        reward = sum([1 if actions[i] == true_labels[i] else -1 for i in range(SEQUENCE_LENGTH)])\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= len(self.data) - 1\n",
    "        obs = np.array(self.data[self.current_step], dtype=np.float32)\n",
    "        return obs, reward, done, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_dir(directory):\n",
    "    all_sequences, all_labels = [], []\n",
    "    for file_name in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        df = pd.read_csv(file_path, sep=\"\\\\s+\", names=[\"time\", \"pressure\", \"label\"])\n",
    "        if df.empty or \"pressure\" not in df:\n",
    "            continue\n",
    "        \n",
    "        for i in range(len(df) - SEQUENCE_LENGTH):\n",
    "            seq = df[\"pressure\"].iloc[i: i + SEQUENCE_LENGTH].values\n",
    "            label_seq = df[\"label\"].iloc[i: i + SEQUENCE_LENGTH].values\n",
    "            all_sequences.append(seq)\n",
    "            all_labels.append(label_seq)\n",
    "\n",
    "    return np.array(all_sequences), np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = load_data_from_dir(TRAIN_DIR)\n",
    "test_files = [os.path.join(TEST_DIR, file) for file in os.listdir(TEST_DIR)]\n",
    "\n",
    "\n",
    "train_env = TimeSeriesEnv(train_data, train_labels)\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=CustomTransformerPolicy,\n",
    "    features_extractor_kwargs=dict(features_dim=128),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO(\"MlpPolicy\", train_env, learning_rate=LEARNING_RATE, verbose=1, device=device, policy_kwargs=policy_kwargs)\n",
    "model.learn(total_timesteps=N_EPISODES * len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инференс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "loaded_model = PPO.load(MODEL_SAVE_PATH, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_dfs = []\n",
    "\n",
    "for test_file in test_files:\n",
    "    df_test = pd.read_csv(test_file, sep=\"\\\\s+\", names=[\"time\", \"pressure\"])\n",
    "    test_sequences = [df_test[\"pressure\"].iloc[i: i + SEQUENCE_LENGTH].values for i in range(len(df_test) - SEQUENCE_LENGTH)]\n",
    "    test_sequences = np.array(test_sequences)\n",
    "    all_predictions = [[] for _ in range(len(df_test))]\n",
    "    for start in range(len(test_sequences)):\n",
    "        pred_classes, _ = loaded_model.predict(test_sequences[start])\n",
    "        \n",
    "        for i in range(SEQUENCE_LENGTH):\n",
    "            if start + i < len(df_test):  \n",
    "                all_predictions[start + i].append(pred_classes[i])\n",
    "\n",
    "    final_classes = np.zeros(len(df_test))\n",
    "    for i in range(len(all_predictions)):\n",
    "        if all_predictions[i]:  \n",
    "            final_classes[i] = Counter(all_predictions[i]).most_common(1)[0][0]  \n",
    "        elif i > 0:  \n",
    "            final_classes[i] = final_classes[i - 1] \n",
    "\n",
    "    df_test[\"prediction\"] = final_classes\n",
    "    predicted_dfs.append(df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
