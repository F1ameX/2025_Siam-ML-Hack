{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "import torch.nn as nn\n",
    "from gym import spaces\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from transformers import BertModel\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\" \n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()\n",
    "    torch.cuda.set_per_process_memory_fraction(0.75, device=0)\n",
    "else:\n",
    "    device =  \"cpu\"\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.manual_seed(52)\n",
    "np.random.seed(52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 100\n",
    "N_EPISODES = 500\n",
    "LEARNING_RATE = 3e-4\n",
    "BATCH_SIZE = 64\n",
    "TRAIN_DIR = \"../src/train_denoised/\"\n",
    "TEST_DIR = \"../src/test_denoised/\"\n",
    "MODEL_SAVE_PATH = \"../models/ppo_transformer_model.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerFeatureExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space, hidden_dim=128, num_layers=2):\n",
    "        super(TransformerFeatureExtractor, self).__init__(observation_space, hidden_dim)\n",
    "\n",
    "        encoder_layers = TransformerEncoderLayer(d_model=hidden_dim, nhead=4)\n",
    "        self.transformer = TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self._features_dim = hidden_dim\n",
    "\n",
    "    def forward(self, observations):\n",
    "        x = observations.permute(1, 0, 2)  \n",
    "        x = self.transformer(x)\n",
    "        x = x.mean(dim=0)  \n",
    "        return self.fc(x)\n",
    "    \n",
    "class TimeSeriesDataset(IterableDataset):\n",
    "    def __init__(self, directory):\n",
    "        self.directory = directory\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.load_data_from_dir()\n",
    "\n",
    "    def load_data_from_dir(self):\n",
    "        for file_name in os.listdir(self.directory):\n",
    "            file_path = os.path.join(self.directory, file_name)\n",
    "            df = pd.read_csv(file_path, sep=\"\\\\s+\", names=[\"time\", \"pressure\", \"label\"])\n",
    "            if df.empty or \"pressure\" not in df:\n",
    "                continue\n",
    "\n",
    "            for i in range(len(df) - SEQUENCE_LENGTH):\n",
    "                seq = df[\"pressure\"].iloc[i: i + SEQUENCE_LENGTH].values.astype(np.float32)\n",
    "                label_seq = df[\"label\"].iloc[i: i + SEQUENCE_LENGTH].values.astype(np.int8)\n",
    "                yield seq, label_seq  # ✅ `yield`, чтобы не загружать всё в память\n",
    "\n",
    "# ⚡ Gym среда\n",
    "class TimeSeriesEnv(gym.Env):\n",
    "    def __init__(self, dataloader):\n",
    "        super(TimeSeriesEnv, self).__init__()\n",
    "        self.dataloader = dataloader\n",
    "        self.iterator = iter(dataloader)\n",
    "        self.observation_space = spaces.Box(low=0.0, high=1.0, shape=(SEQUENCE_LENGTH, 1), dtype=np.float32)\n",
    "        self.action_space = spaces.Discrete(3)  # 3 класса\n",
    "\n",
    "    def reset(self):\n",
    "        try:\n",
    "            self.current_seq, self.current_label = next(self.iterator)\n",
    "        except StopIteration:\n",
    "            self.iterator = iter(self.dataloader)\n",
    "            self.current_seq, self.current_label = next(self.iterator)\n",
    "\n",
    "        self.current_seq = self.current_seq.to(device)  # ✅ Переносим на GPU\n",
    "        self.current_label = self.current_label.to(device)\n",
    "        return self.current_seq.numpy().reshape(-1, 1)\n",
    "\n",
    "    def step(self, action):\n",
    "        correct = (action == self.current_label).float()  # ✅ Правильное предсказание\n",
    "        reward = correct.mean().item()  # ✅ Усредняем награду по всем точкам\n",
    "        done = True\n",
    "        return self.current_seq.numpy().reshape(-1, 1), reward, done, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TimeSeriesDataset(TRAIN_DIR)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env = TimeSeriesEnv(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'TimeSeriesDataset' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 16\u001b[0m\n\u001b[1;32m      1\u001b[0m policy_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m      2\u001b[0m     features_extractor_class\u001b[38;5;241m=\u001b[39mTransformerFeatureExtractor,\n\u001b[1;32m      3\u001b[0m     features_extractor_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m),\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\n\u001b[1;32m      7\u001b[0m     policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     env\u001b[38;5;241m=\u001b[39mtrain_env,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     policy_kwargs\u001b[38;5;241m=\u001b[39mpolicy_kwargs\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m model\u001b[38;5;241m.\u001b[39mlearn(total_timesteps\u001b[38;5;241m=\u001b[39mN_EPISODES \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'TimeSeriesDataset' has no len()"
     ]
    }
   ],
   "source": [
    "policy_kwargs = dict(\n",
    "    features_extractor_class=TransformerFeatureExtractor,\n",
    "    features_extractor_kwargs=dict(hidden_dim=128),\n",
    ")\n",
    "\n",
    "model = PPO(\n",
    "    policy=\"MlpPolicy\",\n",
    "    env=train_env,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    n_epochs=2,\n",
    "    verbose=1,\n",
    "    device=device,\n",
    "    policy_kwargs=policy_kwargs\n",
    ")\n",
    "\n",
    "model.learn(total_timesteps=N_EPISODES * len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инференс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "loaded_model = PPO.load(MODEL_SAVE_PATH, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import torch\n",
    "\n",
    "predicted_dfs = []\n",
    "\n",
    "for test_file in test_files:\n",
    "    df_test = pd.read_csv(test_file, sep=\"\\\\s+\", names=[\"time\", \"pressure\"])\n",
    "    \n",
    "    test_sequences = np.array([\n",
    "        df_test[\"pressure\"].iloc[i: i + SEQUENCE_LENGTH].values\n",
    "        for i in range(len(df_test) - SEQUENCE_LENGTH)\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "    test_sequences = torch.tensor(test_sequences, dtype=torch.float32).to(device)\n",
    "    pred_classes, _ = loaded_model.predict(test_sequences, deterministic=True)\n",
    "\n",
    "    all_predictions = [[] for _ in range(len(df_test))]\n",
    "\n",
    "    for start in range(len(test_sequences)):\n",
    "        for i in range(SEQUENCE_LENGTH):\n",
    "            if start + i < len(df_test):  \n",
    "                all_predictions[start + i].append(int(pred_classes[start, i]))  \n",
    "\n",
    "    final_classes = np.zeros(len(df_test), dtype=int)\n",
    "\n",
    "    for i in range(len(all_predictions)):\n",
    "        if all_predictions[i]:  \n",
    "            final_classes[i] = Counter(all_predictions[i]).most_common(1)[0][0]  \n",
    "        elif i > 0:  \n",
    "            final_classes[i] = final_classes[i - 1] \n",
    "\n",
    "    df_test[\"prediction\"] = final_classes\n",
    "    predicted_dfs.append(df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
