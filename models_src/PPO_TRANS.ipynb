{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "import torch.nn as nn\n",
    "from gym import spaces\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n",
    "torch.cuda.set_per_process_memory_fraction(0.75, device=0)\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.manual_seed(52)\n",
    "np.random.seed(52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 100\n",
    "N_EPISODES = 500\n",
    "LEARNING_RATE = 3e-4\n",
    "BATCH_SIZE = 64\n",
    "TRAIN_DIR = \"../src/train_denoised/\"\n",
    "TEST_DIR = \"../src/test_denoised/\"\n",
    "MODEL_SAVE_PATH = \"../models/ppo_transformer_model.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerFeatureExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space, hidden_dim=128):\n",
    "        super(TransformerFeatureExtractor, self).__init__(observation_space, hidden_dim)\n",
    "        self.transformer = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.fc = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self._features_dim = hidden_dim\n",
    "\n",
    "    def forward(self, observations):\n",
    "        x = self.transformer(observations).last_hidden_state\n",
    "        return self.fc(x[:, -1, :])\n",
    "    \n",
    "class TimeSeriesDataset(IterableDataset):\n",
    "    def __init__(self, directory):\n",
    "        self.directory = directory\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.load_data_from_dir()\n",
    "\n",
    "    def load_data_from_dir(self):\n",
    "        for file_name in os.listdir(self.directory):\n",
    "            file_path = os.path.join(self.directory, file_name)\n",
    "            df = pd.read_csv(file_path, sep=\"\\\\s+\", names=[\"time\", \"pressure\", \"label\"])\n",
    "            if df.empty or \"pressure\" not in df:\n",
    "                continue\n",
    "\n",
    "            for i in range(len(df) - SEQUENCE_LENGTH):\n",
    "                seq = df[\"pressure\"].iloc[i: i + SEQUENCE_LENGTH].values.astype(np.float32)\n",
    "                label_seq = df[\"label\"].iloc[i: i + SEQUENCE_LENGTH].values.astype(np.int8)\n",
    "                yield seq, label_seq  # ✅ `yield`, чтобы не загружать всё в память\n",
    "\n",
    "# ⚡ Gym среда\n",
    "class TimeSeriesEnv(gym.Env):\n",
    "    def __init__(self, dataloader):\n",
    "        super(TimeSeriesEnv, self).__init__()\n",
    "        self.dataloader = dataloader\n",
    "        self.iterator = iter(dataloader)\n",
    "        self.observation_space = spaces.Box(low=0.0, high=1.0, shape=(SEQUENCE_LENGTH, 1), dtype=np.float32)\n",
    "        self.action_space = spaces.Discrete(3)  # 3 класса\n",
    "\n",
    "    def reset(self):\n",
    "        try:\n",
    "            self.current_seq, self.current_label = next(self.iterator)\n",
    "        except StopIteration:\n",
    "            self.iterator = iter(self.dataloader)  # Обновляем итератор, если данные кончились\n",
    "            self.current_seq, self.current_label = next(self.iterator)\n",
    "        return self.current_seq.numpy().reshape(-1, 1)\n",
    "\n",
    "    def step(self, action):\n",
    "        reward = 1 if action == self.current_label else -1\n",
    "        done = True  # PPO работает на эпизодах, не на временных рядах\n",
    "        return self.current_seq.numpy().reshape(-1, 1), reward, done, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚡ DataLoader (загрузка батчами)\n",
    "train_dataset = TimeSeriesDataset(TRAIN_DIR)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env = TimeSeriesEnv(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_kwargs = dict(\n",
    "    features_extractor_class=TransformerFeatureExtractor,\n",
    "    features_extractor_kwargs=dict(hidden_dim=128),\n",
    ")\n",
    "\n",
    "model = PPO(\n",
    "    policy=\"MlpPolicy\",\n",
    "    env=train_env,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    n_epochs=2,\n",
    "    verbose=1,\n",
    "    device=device,\n",
    "    policy_kwargs=policy_kwargs\n",
    ")\n",
    "\n",
    "# ⚡ Обучаем PPO\n",
    "model.learn(total_timesteps=N_EPISODES * len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инференс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "loaded_model = PPO.load(MODEL_SAVE_PATH, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_dfs = []\n",
    "\n",
    "for test_file in test_files:\n",
    "    df_test = pd.read_csv(test_file, sep=\"\\\\s+\", names=[\"time\", \"pressure\"])\n",
    "    test_sequences = [df_test[\"pressure\"].iloc[i: i + SEQUENCE_LENGTH].values for i in range(len(df_test) - SEQUENCE_LENGTH)]\n",
    "    test_sequences = np.array(test_sequences)\n",
    "    all_predictions = [[] for _ in range(len(df_test))]\n",
    "    for start in range(len(test_sequences)):\n",
    "        pred_classes, _ = loaded_model.predict(test_sequences[start])\n",
    "        \n",
    "        for i in range(SEQUENCE_LENGTH):\n",
    "            if start + i < len(df_test):  \n",
    "                all_predictions[start + i].append(pred_classes[i])\n",
    "\n",
    "    final_classes = np.zeros(len(df_test))\n",
    "    for i in range(len(all_predictions)):\n",
    "        if all_predictions[i]:  \n",
    "            final_classes[i] = Counter(all_predictions[i]).most_common(1)[0][0]  \n",
    "        elif i > 0:  \n",
    "            final_classes[i] = final_classes[i - 1] \n",
    "\n",
    "    df_test[\"prediction\"] = final_classes\n",
    "    predicted_dfs.append(df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
